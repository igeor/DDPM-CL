{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.kid import KernelInceptionDistance\n",
    "from torchmetrics.image.mifid import MemorizationInformedFrechetInceptionDistance\n",
    "\n",
    "from dataset import init_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = \"/datatmp/users/igeorvasilis/ddpm-continual-learning/results/cifar10/0_from_1/\"\n",
    "\n",
    "args_dir = os.path.join(experiment_dir, \"args.pt\")\n",
    "args = torch.load(args_dir)\n",
    "args.device = 'cuda:2'\n",
    "args.dataset_path = \"/datatmp/users/igeorvasilis/datasets/cifar10\"\n",
    "\n",
    "args.pretrained_model_dir = os.path.join(experiment_dir, \"epoch-200\")\n",
    "args.train_log_dir = os.path.join(experiment_dir, \"train_log.pt\")\n",
    "args.folder_name = \"ddim_fake_images\"\n",
    "\n",
    "train_log = torch.load(args.train_log_dir)\n",
    "\n",
    "torch.manual_seed(args.gen_seed)\n",
    "np.random.seed(args.gen_seed)\n",
    "random.seed(args.gen_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "import json\n",
    "\n",
    "with open(f\"{args.pretrained_model_dir}/unet/config.json\") as f:\n",
    "    # load json, 'r') as f:\n",
    "    config = json.load(f)\n",
    "config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print args values\n",
    "print(\"Arguments:\")\n",
    "for k, v in vars(args).items():\n",
    "    print(f\"\\t{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frechet Inception Distance (FID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([ transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all fake images from the corresponding directory \n",
    "fake_images_dir = f'{args.pretrained_model_dir}/{args.folder_name}'\n",
    "fake_images_list = os.listdir(fake_images_dir)\n",
    "n_fake_images = len(fake_images_list)\n",
    "\n",
    "# Create eval dataloader\n",
    "trainset, testset = init_dataset(dataset_name=args.dataset_name, dataset_path=args.dataset_path, \n",
    "                                 labels=args.labels, preprocess=transforms.Compose([ transforms.ToTensor()]))\n",
    "\n",
    "# trainset = torch.utils.data.ConcatDataset([trainset, testset])\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=args.eval_batch_size, shuffle=True)\n",
    "\n",
    "# Define FID metric\n",
    "fid = FrechetInceptionDistance(feature=2048, normalize=True).to(args.device)\n",
    "\n",
    "# Iterate over all fake images\n",
    "n_images_to_eval = min(len(fake_images_list), len(eval_dataloader.dataset))\n",
    "for batch_idx in tqdm(range(0, n_images_to_eval, args.eval_batch_size), \n",
    "                      desc=f'Calculating FID for {n_images_to_eval} images...'):\n",
    "    \n",
    "    # Get the real images\n",
    "    real_images, _ = next(iter(eval_dataloader))\n",
    "    real_images = real_images.to(args.device)\n",
    "\n",
    "    # Get the fake images\n",
    "    fake_images = [read_image(f\"{fake_images_dir}/{i}\") for i in fake_images_list[batch_idx:batch_idx+args.eval_batch_size]]\n",
    "    fake_images = torch.stack(fake_images).to(args.device) \n",
    "    fake_images = fake_images.float() / 255.0\n",
    "    \n",
    "    real_images = real_images[:fake_images.shape[0]]\n",
    "\n",
    "    # Update the FID metric\n",
    "    fid.update(real_images, real=True)\n",
    "    fid.update(fake_images, real=False)\n",
    "\n",
    "# Compute the FID score\n",
    "print(fid.compute())\n",
    "fid.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Inception Distance (KID) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all fake images from the corresponding directory \n",
    "fake_images_dir = f'{args.pretrained_model_dir}/{args.folder_name}'\n",
    "fake_images_list = os.listdir(fake_images_dir)\n",
    "n_fake_images = len(fake_images_list)\n",
    "\n",
    "# Create eval dataloader\n",
    "trainset, testset = init_dataset(dataset_name=args.dataset_name, dataset_path=args.dataset_path, \n",
    "                                 labels=args.labels, preprocess=transforms.Compose([ transforms.ToTensor()]))\n",
    "\n",
    "# trainset = torch.utils.data.ConcatDataset([trainset, testset])\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=args.eval_batch_size, shuffle=True)\n",
    "\n",
    "# Define kid metric\n",
    "subsets = 100\n",
    "subset_size = 1000\n",
    "kid = KernelInceptionDistance(\n",
    "    feature=2048, \n",
    "    normalize=True,\n",
    "    subsets=subsets,\n",
    "    subset_size=subset_size\n",
    ").to(args.device)\n",
    "\n",
    "# Iterate over all fake images\n",
    "n_images_to_eval = min(len(fake_images_list), len(eval_dataloader.dataset))\n",
    "for batch_idx in tqdm(range(0, n_images_to_eval, args.eval_batch_size), desc='Calculating kid...'):\n",
    "    \n",
    "    # Get the corresponding real images\n",
    "    real_images, _ = next(iter(eval_dataloader))\n",
    "    real_images = real_images.to(args.device)\n",
    "\n",
    "    # Get the fake images\n",
    "    fake_images = [read_image(f\"{fake_images_dir}/{i}\") for i in fake_images_list[batch_idx:batch_idx+args.eval_batch_size]]\n",
    "    fake_images = torch.stack(fake_images).to(args.device) \n",
    "    fake_images = fake_images.float() / 255.0\n",
    "\n",
    "    # Update the kid metric\n",
    "    kid.update(real_images, real=True)\n",
    "    kid.update(fake_images, real=False)\n",
    "\n",
    "# Compute the kid score\n",
    "print(kid.compute())\n",
    "kid.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, _ = init_dataset(dataset_name=args.dataset_name, dataset_path=args.dataset_path, labels=args.labels, preprocess=preprocess)\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=args.eval_batch_size, shuffle=True)\n",
    "\n",
    "real_images = torch.cat([image for image, _ in eval_dataloader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all fake images from the corresponding directory \n",
    "fake_images_dir = f'{args.pretrained_model_dir}/{args.folder_name}'\n",
    "fake_images_list = os.listdir(fake_images_dir)\n",
    "fake_images = torch.stack([read_image(f'{fake_images_dir}/{i}') for i in fake_images_list])\n",
    "fake_images = fake_images.float() / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images_to_eval = min(real_images.shape[0], fake_images.shape[0])\n",
    "real_images = real_images[:n_images_to_eval]\n",
    "fake_images = fake_images[:n_images_to_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from improved_precision_recall import IPR \n",
    "\n",
    "# Define IPR metric\n",
    "ipr = IPR(batch_size=8, k=3, num_samples=n_images_to_eval, device=args.device)\n",
    "\n",
    "# Compute Manifold \n",
    "ipr.compute_manifold_ref(real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = ipr.precision_and_recall(fake_images)\n",
    "# Print results\n",
    "print('precision =', metric.precision)\n",
    "print('recall =', metric.recall)\n",
    "\n",
    "# r_score = ipr.realism(fake_images)\n",
    "# print('realism =', r_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModelForImageClassification\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from utils import get_preprocess_function\n",
    "args.device = 'cuda:1'\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\"nateraw/vit-base-patch16-224-cifar10\").to(args.device)\n",
    "preprocess = get_preprocess_function(\"EvalCifar10\")\n",
    "\n",
    "pred_labels = {label:0 for label in args.labels}\n",
    "pred_labels['no'] = 0\n",
    "\n",
    "for b_idx in tqdm(range(0, len(fake_images_list), args.eval_batch_size)):\n",
    "    \n",
    "    fake_images_names = fake_images_list[b_idx:b_idx+args.eval_batch_size]\n",
    "    fake_images = [ read_image(f'{fake_images_dir}/{fi_name}') for fi_name in fake_images_names ]\n",
    "    fake_images = [ preprocess(image) for image in fake_images ]\n",
    "    fake_images = torch.stack(fake_images)\n",
    "    fake_images = fake_images.float() / 255.0\n",
    "\n",
    "    # Get predictions\n",
    "    outputs = model(fake_images.to(args.device))\n",
    "    outputs = torch.softmax(outputs.logits, dim=1)\n",
    "    predicted = torch.argmax(outputs, dim=1).cpu().numpy()    \n",
    "    for label in predicted: \n",
    "        if label in pred_labels: pred_labels[label] += 1\n",
    "        else: pred_labels['no'] += 1\n",
    "\n",
    "# Compute the total count of all labels\n",
    "total_count = sum(pred_labels.values())\n",
    "# Compute the frequency of each label\n",
    "frequencies = {label: count / total_count for label, count in pred_labels.items()}\n",
    "print(\"Frequencies:\", frequencies)\n",
    "\n",
    "# Compute the entropy\n",
    "entropy = -sum([p * math.log(p) for p in frequencies.values()])\n",
    "print(\"Entropy:\", entropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "checkpoint = torch.load('/datatmp/users/igeorvasilis/ddpm-continual-learning/results/mnist/eval_classifier/checkpoint_1n2.pth')\n",
    "\n",
    "# Load the actual and the opposite mapping\n",
    "map_labels = checkpoint['mapping']\n",
    "map_labels_inv = {v: k for k, v in map_labels.items()}\n",
    "\n",
    "# Define the pretrained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(args.labels))\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all fake images from the corresponding directory \n",
    "fake_images_dir = f'{args.pretrained_model_dir}/{args.folder_name}'\n",
    "fake_images_list = os.listdir(fake_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "\n",
    "n_counts = {label:0 for label in map_labels.keys()}\n",
    "\n",
    "for b_idx in tqdm(range(0, len(fake_images_list), args.eval_batch_size)):\n",
    "    \n",
    "    fake_images_names = fake_images_list[b_idx:b_idx+args.eval_batch_size]\n",
    "    fake_images = [ read_image(f'{fake_images_dir}/{fi_name}') for fi_name in fake_images_names ]\n",
    "    fake_images = torch.stack(fake_images)\n",
    "    fake_images = fake_images.float() / 255.0\n",
    "\n",
    "    # Get predictions\n",
    "    outputs = model(fake_images.to(args.device))\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    predicted = [map_labels_inv[label.item()] for label in predicted]\n",
    "    for label in predicted: n_counts[label] += 1\n",
    "\n",
    "# Compute the total count of all labels\n",
    "total_count = sum(n_counts.values())\n",
    "# Compute the frequency of each label\n",
    "frequencies = {label: count / total_count for label, count in n_counts.items()}\n",
    "print(\"Frequencies:\", frequencies)\n",
    "\n",
    "# Compute the entropy\n",
    "entropy = -sum([p * math.log(p) for p in frequencies.values()])\n",
    "print(\"Entropy:\", entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from diffusers.utils import make_image_grid\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "fakes = [transforms.ToPILImage()(image) for image in fake_images[:32]]\n",
    "grid = make_image_grid(fakes, rows=4, cols=8)\n",
    "axes[0].imshow(grid); axes[0].set_title(f'Fake images')\n",
    "axes[0].axis('off')\n",
    "\n",
    "reals = [transforms.ToPILImage()(image) for image in real_images[:32]]\n",
    "grid = make_image_grid(reals, rows=4, cols=8)\n",
    "axes[1].imshow(grid); axes[1].set_title(f'Real images')\n",
    "axes[1].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
