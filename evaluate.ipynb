{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "from dataset import init_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import EvalConfig\n",
    "config = EvalConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set manual seed so that we have the same train/test split\n",
    "torch.manual_seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.pretrained_model_dir = 'results/unetSM/mnist-7/epoch-100'\n",
    "config.folder_name = 'ddim_fake_images'\n",
    "config.dataset_name = \"~/.pytorch/MNIST_data/\"\n",
    "config.labels = [7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frechet Inception Distance (FID)\n",
    "* Requires directory of fake images\n",
    "* Requires dataloader reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all fake images from the corresponding directory \n",
    "fake_images_dir = f'./{config.pretrained_model_dir}/{config.folder_name}'\n",
    "fake_images_list = os.listdir(fake_images_dir)\n",
    "n_fake_images = len(fake_images_list)\n",
    "\n",
    "# List (via datalaoder) all real images from the corresponding dataset\n",
    "config.eval_batch_size = 64 \n",
    "\n",
    "# Create eval dataloader\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    init_dataset(config.dataset_name, split='train', labels=config.labels), \n",
    "    batch_size=config.eval_batch_size, shuffle=True)\n",
    "\n",
    "# Define FID metric\n",
    "fid = FrechetInceptionDistance(feature=2048, normalize=True).to(config.device)\n",
    "\n",
    "# Iterate over all fake images\n",
    "n_images_to_eval = min(len(fake_images_list), len(eval_dataloader.dataset))\n",
    "for batch_idx in tqdm(range(0, n_images_to_eval, config.eval_batch_size), desc='Calculating FID...'):\n",
    "    \n",
    "    # Get the corresponding real images\n",
    "    real_images, _ = next(iter(eval_dataloader))\n",
    "    real_images = real_images.to(config.device)\n",
    "\n",
    "    # Get the fake images\n",
    "    fake_images = [read_image(f\"{fake_images_dir}/{i}\") for i in fake_images_list[batch_idx:batch_idx+config.eval_batch_size]]\n",
    "    fake_images = torch.stack(fake_images).to(config.device) \n",
    "    fake_images = fake_images.float() / 255.0\n",
    "    \n",
    "    # Keep the real images of the same size\n",
    "    real_images = real_images[:fake_images.shape[0]]\n",
    "\n",
    "    # Update the FID metric\n",
    "    fid.update(real_images, real=True)\n",
    "    fid.update(fake_images, real=False)\n",
    "\n",
    "# Compute the FID score\n",
    "print(fid.compute())\n",
    "fid.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all real images (via datalaoder) from the corresponding dataset\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    init_dataset(config.dataset_name, split='train', labels=config.labels), \n",
    "    batch_size=config.eval_batch_size, shuffle=True)\n",
    "\n",
    "real_images = torch.cat([image for image, _ in eval_dataloader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all fake images from the corresponding directory \n",
    "fake_images_dir = f'./{config.pretrained_model_dir}/{config.folder_name}'\n",
    "fake_images_list = os.listdir(fake_images_dir)\n",
    "fake_images = torch.stack([read_image(f'{fake_images_dir}/{i}') for i in fake_images_list])\n",
    "fake_images = fake_images.float() / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images_to_eval = min(real_images.shape[0], fake_images.shape[0])\n",
    "real_images = real_images[:n_images_to_eval]\n",
    "fake_images = fake_images[:n_images_to_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from improved_precision_recall import IPR \n",
    "\n",
    "# Define IPR metric\n",
    "ipr = IPR(batch_size=8, k=3, num_samples=n_images_to_eval, device='cuda')\n",
    "\n",
    "# Compute Manifold \n",
    "ipr.compute_manifold_ref(real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = ipr.precision_and_recall(fake_images)\n",
    "# Print results\n",
    "print('precision =', metric.precision)\n",
    "print('recall =', metric.recall)\n",
    "\n",
    "# r_score = ipr.realism(fake_images)\n",
    "# print('realism =', r_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "checkpoint = torch.load('./results/eval_classifier/checkpoint_2n7.pth')\n",
    "\n",
    "# Load the actual and the opposite mapping\n",
    "map_labels = checkpoint['mapping']\n",
    "map_labels_inv = {v: k for k, v in map_labels.items()}\n",
    "\n",
    "# Define the pretrained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(config.labels))\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all fake images from the corresponding directory \n",
    "fake_images_dir = f'./{config.pretrained_model_dir}/{config.folder_name}'\n",
    "fake_images_list = os.listdir(fake_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "\n",
    "n_counts = {label:0 for label in map_labels.keys()}\n",
    "\n",
    "for b_idx in tqdm(range(0, len(fake_images_list), config.eval_batch_size)):\n",
    "    \n",
    "    fake_images_names = fake_images_list[b_idx:b_idx+config.eval_batch_size]\n",
    "    fake_images = [ read_image(f'{fake_images_dir}/{fi_name}') for fi_name in fake_images_names ]\n",
    "    fake_images = torch.stack(fake_images)\n",
    "    fake_images = fake_images.float() / 255.0\n",
    "\n",
    "    # Get predictions\n",
    "    outputs = model(fake_images.to(config.device))\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    predicted = [map_labels_inv[label.item()] for label in predicted]\n",
    "    for label in predicted: n_counts[label] += 1\n",
    "\n",
    "# Compute the total count of all labels\n",
    "total_count = sum(n_counts.values())\n",
    "# Compute the frequency of each label\n",
    "frequencies = {label: count / total_count for label, count in n_counts.items()}\n",
    "print(\"Frequencies:\", frequencies)\n",
    "\n",
    "# Compute the entropy\n",
    "entropy = -sum([p * math.log(p) for p in frequencies.values()])\n",
    "print(\"Entropy:\", entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from diffusers.utils import make_image_grid\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "fakes = [transforms.ToPILImage()(image) for image in fake_images[:32]]\n",
    "grid = make_image_grid(fakes, rows=4, cols=8)\n",
    "axes[0].imshow(grid); axes[0].set_title(f'Fake images')\n",
    "\n",
    "reals = [transforms.ToPILImage()(image) for image in real_images[:32]]\n",
    "grid = make_image_grid(reals, rows=4, cols=8)\n",
    "axes[1].imshow(grid); axes[1].set_title(f'Real images')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
